{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396d20bd",
   "metadata": {},
   "source": [
    "# Homework 2 - Serving a Machine Learning Model as an API Service\n",
    "\n",
    "Mikołaj Marmurowicz 151956"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab25fff",
   "metadata": {},
   "source": [
    "## Loading required libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d23e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import lightning as L\n",
    "import bentoml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577c5c0",
   "metadata": {},
   "source": [
    "Recreating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0644de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitFashionMNIST(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float = 1e-3,\n",
    "        dropout: float = 0.3,\n",
    "        hidden_size: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 10)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch, stage: str):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(f\"{stage}_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=3\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\"\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b3ca8",
   "metadata": {},
   "source": [
    "Loading the model from a previously created checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58c8999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Lightning model.\n",
      "Hyperparameters: \"dropout\":     0.2266455049847091\n",
      "\"hidden_size\": 256\n",
      "\"lr\":          0.0008339802352744992\n"
     ]
    }
   ],
   "source": [
    "CKPT_PATH = \"..\\\\Homework1\\\\pl_hw1_fashionmnist\\\\3sahzi9m\\\\checkpoints\\\\fashionmnist-optuna-epoch=05-val_loss=0.1950.ckpt\"  \n",
    "\n",
    "lit_model = LitFashionMNIST.load_from_checkpoint(CKPT_PATH)\n",
    "lit_model.to(\"cuda\")\n",
    "lit_model.eval()\n",
    "\n",
    "print(\"Loaded Lightning model.\")\n",
    "print(\"Hyperparameters:\", lit_model.hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ab60e",
   "metadata": {},
   "source": [
    "Quick check whether the model can predict values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dadf1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels: [1, 5, 5, 6]\n",
      "Preds      : [1, 5, 5, 0]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(test_loader))\n",
    "device = next(lit_model.parameters()).device\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = lit_model(images)\n",
    "    preds = logits.argmax(dim=1)\n",
    "\n",
    "print(\"True labels:\", labels.tolist())\n",
    "print(\"Preds      :\", preds.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2c7be",
   "metadata": {},
   "source": [
    "## Saving the model to BentoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593b29e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikim\\AppData\\Local\\Temp\\ipykernel_9144\\2205286946.py:1: BentoMLDeprecationWarning: `bentoml.pytorch` is deprecated since v1.4 and will be removed in a future version.\n",
      "  bento_tag = bentoml.pytorch.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model tag: Model(tag=\"fashion_mnist_lit:adjznmwip272pkab\")\n"
     ]
    }
   ],
   "source": [
    "bento_tag = bentoml.pytorch.save_model(\n",
    "    \"fashion_mnist_lit\",\n",
    "    lit_model,\n",
    "    signatures={\n",
    "        \"__call__\": {\"batchable\": True}\n",
    "    },\n",
    "    metadata={\n",
    "        \"source\": \"HW1 LitFashionMNIST\",\n",
    "        \"framework\": \"pytorch_lightning\",\n",
    "        \"dataset\": \"FashionMNIST\",\n",
    "        \"task\": \"image_classification\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Saved model tag:\", bento_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8869165",
   "metadata": {},
   "source": [
    "Checking if it exists within terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d94dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tag                            Module           Size      Creation Time       \n",
      " fashion_mnist_lit:adjznmwip2…  bentoml.pytorch  3.16 MiB  2025-11-23 16:06:35 \n",
      " fashion_mnist_lit:5xdcezwipw…  bentoml.pytorch  3.16 MiB  2025-11-23 16:06:03 \n",
      " fashion_mnist_lit:vg6qhcgipw…  bentoml.pytorch  3.16 MiB  2025-11-23 16:04:09 \n",
      " fashion_mnist_lit:6dlzrwwipo…  bentoml.pytorch  3.16 MiB  2025-11-23 15:51:49 \n",
      "name: fashion_mnist_lit\n",
      "version: adjznmwip272pkab\n",
      "module: bentoml.pytorch\n",
      "labels: {}\n",
      "options:\n",
      "  partial_kwargs: {}\n",
      "metadata:\n",
      "  source: HW1 LitFashionMNIST\n",
      "  framework: pytorch_lightning\n",
      "  dataset: FashionMNIST\n",
      "  task: image_classification\n",
      "context:\n",
      "  framework_name: torch\n",
      "  framework_versions:\n",
      "    torch: 2.5.1\n",
      "  bentoml_version: 1.4.29\n",
      "  python_version: 3.11.14\n",
      "signatures:\n",
      "  __call__:\n",
      "    batchable: true\n",
      "    batch_dim:\n",
      "    - 0\n",
      "    - 0\n",
      "api_version: v1\n",
      "creation_time: '2025-11-23T15:06:35.386490+00:00'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bentoml models list\n",
    "!bentoml models get fashion_mnist_lit:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fff28d",
   "metadata": {},
   "source": [
    "The code for service.py file is as follows:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import bentoml\n",
    "\n",
    "MODEL_TAG = \"fashion_mnist_lit:latest\"\n",
    "\n",
    "@bentoml.service\n",
    "class FashionMNISTService:\n",
    "    def __init__(self) -> None:\n",
    "        device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(device_str)\n",
    "        self.model = bentoml.pytorch.load_model(MODEL_TAG, device_id=device_str)\n",
    "        self.model.eval()\n",
    "\n",
    "    @bentoml.api\n",
    "    def predict(self, images: torch.Tensor) -> list[int]:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(self.device)\n",
    "            logits = self.model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        return preds.cpu().tolist()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16353974",
   "metadata": {},
   "source": [
    "Running the service in a seperate window command line via:\n",
    "```bash\n",
    "bentoml serve\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9badce",
   "metadata": {},
   "source": [
    "## Testing the served model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e082fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1\n",
      "Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "img, label = test_dataset[5]\n",
    "batch = img.unsqueeze(0)\n",
    "\n",
    "with bentoml.SyncHTTPClient(\"http://localhost:3000\") as client:\n",
    "    preds = client.predict(batch)\n",
    "    print(\"True label:\", label)\n",
    "    print(\"Predicted:\", preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa556bb",
   "metadata": {},
   "source": [
    "As we can see the model is able to successfully connect via the BentoML client to the serviced model and provide its predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
